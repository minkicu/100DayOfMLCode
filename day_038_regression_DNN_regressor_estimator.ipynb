{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day_038_regression_DNN_regressor_estimator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkrissada/100DayOfMLCode/blob/master/day_038_regression_DNN_regressor_estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ML4aa_pLoffr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "\n",
        "COLUMN_TYPES = collections.OrderedDict([\n",
        "    (\"symboling\", int),\n",
        "    (\"normalized-losses\", float),\n",
        "    (\"make\", str),\n",
        "    (\"fuel-type\", str),\n",
        "    (\"aspiration\", str),\n",
        "    (\"num-of-doors\", str),\n",
        "    (\"body-style\", str),\n",
        "    (\"drive-wheels\", str),\n",
        "    (\"engine-location\", str),\n",
        "    (\"wheel-base\", float),\n",
        "    (\"length\", float),\n",
        "    (\"width\", float),\n",
        "    (\"height\", float),\n",
        "    (\"curb-weight\", float),\n",
        "    (\"engine-type\", str),\n",
        "    (\"num-of-cylinders\", str),\n",
        "    (\"engine-size\", float),\n",
        "    (\"fuel-system\", str),\n",
        "    (\"bore\", float),\n",
        "    (\"stroke\", float),\n",
        "    (\"compression-ratio\", float),\n",
        "    (\"horsepower\", float),\n",
        "    (\"peak-rpm\", float),\n",
        "    (\"city-mpg\", float),\n",
        "    (\"highway-mpg\", float),\n",
        "    (\"price\", float)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XxTo8ZjFp416",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def raw_dataframe():\n",
        "  \"\"\"Load the automobile data set as a pd.DataFrame.\"\"\"\n",
        "  # Download and cache the data\n",
        "  path = tf.keras.utils.get_file(URL.split(\"/\")[-1], URL)\n",
        "\n",
        "  # Load it into a pandas DataFrame\n",
        "  df = pd.read_csv(path, names=COLUMN_TYPES.keys(),\n",
        "                   dtype=COLUMN_TYPES, na_values=\"?\")\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P9JiH8wppsXT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(y_name=\"price\", train_fraction=0.7, seed=None):\n",
        "  # Load the raw data columns.\n",
        "  data = raw_dataframe()\n",
        "\n",
        "  # Delete rows with unknowns\n",
        "  data = data.dropna()\n",
        "\n",
        "  # Shuffle the data\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  # Split the data into train/test subsets.\n",
        "  x_train = data.sample(frac=train_fraction, random_state=seed)\n",
        "  x_test = data.drop(x_train.index)\n",
        "\n",
        "  # Extract the label from the features DataFrame.\n",
        "  y_train = x_train.pop(y_name)\n",
        "  y_test = x_test.pop(y_name)\n",
        "\n",
        "  return (x_train, y_train), (x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tDN06FW_qbB8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_dataset(batch_sz, x, y=None, shuffle=False, shuffle_buffer_size=1000):\n",
        "\n",
        "\n",
        "    def input_fn():\n",
        "        if y is not None:\n",
        "            dataset = tf.data.Dataset.from_tensor_slices((dict(x), y))\n",
        "        else:\n",
        "            dataset = tf.data.Dataset.from_tensor_slices(dict(x))\n",
        "        if shuffle:\n",
        "            dataset = dataset.shuffle(shuffle_buffer_size).batch(batch_sz).repeat()\n",
        "        else:\n",
        "            dataset = dataset.batch(batch_sz)\n",
        "        return dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "    return input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-tApCFe9qh14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RA1uf_FLof9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2689
        },
        "outputId": "f82a2359-1532-42f7-d4eb-cf2ff5f33869"
      },
      "cell_type": "code",
      "source": [
        "(train_x,train_y), (test_x, test_y) = load_data()\n",
        "\n",
        "train_y /= 1000.\n",
        "test_y /= 1000.\n",
        "\n",
        "# Provide the training input dataset.\n",
        "train_input_fn = make_dataset(100, train_x, train_y, True, 1000)\n",
        "\n",
        "# Provide the validation input dataset.\n",
        "test_input_fn = make_dataset(100, test_x, test_y)\n",
        "\n",
        "# Use the same categorical columns as in `linear_regression_categorical`\n",
        "body_style_vocab = [\"hardtop\", \"wagon\", \"sedan\", \"hatchback\", \"convertible\"]\n",
        "body_style_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "      key=\"body-style\", vocabulary_list=body_style_vocab)\n",
        "make_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "      key=\"make\", hash_bucket_size=50)\n",
        "\n",
        "feature_columns = [\n",
        "      tf.feature_column.numeric_column(key=\"curb-weight\"),\n",
        "      tf.feature_column.numeric_column(key=\"highway-mpg\"),\n",
        "      # Since this is a DNN model, categorical columns must be converted from\n",
        "      # sparse to dense.\n",
        "      # Wrap them in an `indicator_column` to create a\n",
        "      # one-hot vector from the input.\n",
        "      tf.feature_column.indicator_column(body_style_column),\n",
        "      # Or use an `embedding_column` to create a trainable vector for each\n",
        "      # index.\n",
        "      tf.feature_column.embedding_column(make_column, dimension=3),\n",
        "]\n",
        "\n",
        "# Build a DNNRegressor, with 2x20-unit hidden layers, with the feature columns\n",
        "# defined above as input.\n",
        "model = tf.estimator.DNNRegressor(\n",
        "      hidden_units=[20, 20], feature_columns=feature_columns)\n",
        "\n",
        "# Train the model.\n",
        "# By default, the Estimators log output every 100 steps.\n",
        "model.train(input_fn=train_input_fn, steps=5000)\n",
        "\n",
        "# Evaluate how the model performs on data it has not yet seen.\n",
        "eval_result = model.evaluate(input_fn=test_input_fn)\n",
        "\n",
        "# The evaluation returns a Python dictionary. The \"average_loss\" key holds the\n",
        "# Mean Squared Error (MSE).\n",
        "average_loss = eval_result[\"average_loss\"]\n",
        "\n",
        "# Convert MSE to Root Mean Square Error (RMSE).\n",
        "print(\"\\n\" + 80 * \"*\")\n",
        "print(\"\\nRMS error for the test set: ${:.0f}\"\n",
        "        .format(1000. * average_loss**0.5))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpe1qfdech\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpe1qfdech', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe56f15feb8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2997: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpe1qfdech/model.ckpt.\n",
            "INFO:tensorflow:loss = 24174726.0, step = 1\n",
            "INFO:tensorflow:global_step/sec: 373.26\n",
            "INFO:tensorflow:loss = 2146.973, step = 101 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 544.994\n",
            "INFO:tensorflow:loss = 1902.0448, step = 201 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.831\n",
            "INFO:tensorflow:loss = 2088.6462, step = 301 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 505.002\n",
            "INFO:tensorflow:loss = 1826.8123, step = 401 (0.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.073\n",
            "INFO:tensorflow:loss = 1933.1298, step = 501 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.441\n",
            "INFO:tensorflow:loss = 1759.8185, step = 601 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 517.829\n",
            "INFO:tensorflow:loss = 1775.479, step = 701 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.927\n",
            "INFO:tensorflow:loss = 1669.2556, step = 801 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.079\n",
            "INFO:tensorflow:loss = 1717.0082, step = 901 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.414\n",
            "INFO:tensorflow:loss = 1583.0802, step = 1001 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 531.366\n",
            "INFO:tensorflow:loss = 1386.5654, step = 1101 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.296\n",
            "INFO:tensorflow:loss = 1467.192, step = 1201 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.339\n",
            "INFO:tensorflow:loss = 1345.9298, step = 1301 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.798\n",
            "INFO:tensorflow:loss = 1336.0618, step = 1401 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.692\n",
            "INFO:tensorflow:loss = 1191.0879, step = 1501 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.037\n",
            "INFO:tensorflow:loss = 1158.9031, step = 1601 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.686\n",
            "INFO:tensorflow:loss = 1130.8195, step = 1701 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.828\n",
            "INFO:tensorflow:loss = 988.75226, step = 1801 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.045\n",
            "INFO:tensorflow:loss = 944.46747, step = 1901 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.639\n",
            "INFO:tensorflow:loss = 727.95135, step = 2001 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.593\n",
            "INFO:tensorflow:loss = 836.4067, step = 2101 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.05\n",
            "INFO:tensorflow:loss = 787.70483, step = 2201 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 534.037\n",
            "INFO:tensorflow:loss = 728.3202, step = 2301 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.551\n",
            "INFO:tensorflow:loss = 673.17896, step = 2401 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 545.308\n",
            "INFO:tensorflow:loss = 643.54236, step = 2501 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.962\n",
            "INFO:tensorflow:loss = 622.07367, step = 2601 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.725\n",
            "INFO:tensorflow:loss = 597.66064, step = 2701 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.785\n",
            "INFO:tensorflow:loss = 537.25415, step = 2801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.856\n",
            "INFO:tensorflow:loss = 469.67978, step = 2901 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 526.897\n",
            "INFO:tensorflow:loss = 534.8243, step = 3001 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.84\n",
            "INFO:tensorflow:loss = 513.6108, step = 3101 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 557.358\n",
            "INFO:tensorflow:loss = 503.65878, step = 3201 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.921\n",
            "INFO:tensorflow:loss = 496.19147, step = 3301 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.477\n",
            "INFO:tensorflow:loss = 490.0666, step = 3401 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 513.612\n",
            "INFO:tensorflow:loss = 465.0858, step = 3501 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 514.585\n",
            "INFO:tensorflow:loss = 465.04526, step = 3601 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.555\n",
            "INFO:tensorflow:loss = 450.33063, step = 3701 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.891\n",
            "INFO:tensorflow:loss = 426.0384, step = 3801 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.838\n",
            "INFO:tensorflow:loss = 445.45776, step = 3901 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.294\n",
            "INFO:tensorflow:loss = 433.0829, step = 4001 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.883\n",
            "INFO:tensorflow:loss = 230.75572, step = 4101 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 538.009\n",
            "INFO:tensorflow:loss = 423.1259, step = 4201 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.932\n",
            "INFO:tensorflow:loss = 417.0236, step = 4301 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 512.762\n",
            "INFO:tensorflow:loss = 426.29916, step = 4401 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 528.318\n",
            "INFO:tensorflow:loss = 413.5625, step = 4501 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.287\n",
            "INFO:tensorflow:loss = 394.2823, step = 4601 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.167\n",
            "INFO:tensorflow:loss = 375.9653, step = 4701 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 548.487\n",
            "INFO:tensorflow:loss = 407.60367, step = 4801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 529.261\n",
            "INFO:tensorflow:loss = 383.4695, step = 4901 (0.186 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpe1qfdech/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 11.398349.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-03-17T12:49:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpe1qfdech/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-03-17-12:49:23\n",
            "INFO:tensorflow:Saving dict for global step 5000: average_loss = 6.89872, global_step = 5000, label/mean = 13.188729, loss = 331.13855, prediction/mean = 13.435295\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpe1qfdech/model.ckpt-5000\n",
            "\n",
            "********************************************************************************\n",
            "\n",
            "RMS error for the test set: $2627\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}