{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day_060_distributed_training_and_monitoring.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkrissada/100DayOfMLCode/blob/master/day_060_distributed_training_and_monitoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4-5qLn9wmkvc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distributed training and monitoring\n",
        "\n",
        "we refactor to call train_and_evaluate instead of hand-coding our ML pipeline. This allows us to carry out evaluation as part of our training loop instead of as a separate step. It also adds in failure-handling that is necessary for distributed training capabilities."
      ]
    },
    {
      "metadata": {
        "id": "tnSmeaa3mmBW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFYwe03Jn7Db",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Input\n",
        "\n",
        "that we are reading in batches. Instead of using Pandas, we will use Datasets."
      ]
    },
    {
      "metadata": {
        "id": "1qBpvib8pJNx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "csv_columns = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
        "label_column = 'fare_amount'\n",
        "defaults = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
        "\n",
        "def read_dataset(filename, mode, batch_size = 512):\n",
        "  def _input_fn():\n",
        "    def decode_csv(value_column):\n",
        "      columns = tf.decode_csv(value_column,record_defaults = defaults)\n",
        "      features = dict(zip(csv_columns, columns))\n",
        "      label = features.pop(label_column)\n",
        "      return features, label\n",
        "    \n",
        "    file_list = tf.gfile.Glob(filename)\n",
        "    \n",
        "    dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      num_epochs = None\n",
        "      dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
        "    else:\n",
        "      num_epochs = 1\n",
        "    \n",
        "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
        "    return dataset.make_one_shot_iterator().get_next()\n",
        "  return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VhDBPWyvFl2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create features out of input data\n",
        "\n",
        "For now, pass these through."
      ]
    },
    {
      "metadata": {
        "id": "g1k3fCJlvi1N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_columns = [\n",
        "    tf.feature_column.numeric_column('pickuplon'),\n",
        "    tf.feature_column.numeric_column('pickuplat'),\n",
        "    tf.feature_column.numeric_column('dropofflat'),\n",
        "    tf.feature_column.numeric_column('dropofflon'),\n",
        "    tf.feature_column.numeric_column('passengers'),\n",
        "]\n",
        "\n",
        "def add_more_features(feats):\n",
        "  return feats\n",
        "\n",
        "feature_cols = add_more_features(input_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9C9izSZwz6u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### train_and_evaluate"
      ]
    },
    {
      "metadata": {
        "id": "NIfStRG_w6ZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def serving_input_fn():\n",
        "  feature_placeholders = {\n",
        "      'pickuplon' : tf.placeholder(tf.float32, [None]),\n",
        "      'pickuplat' : tf.placeholder(tf.float32, [None]),\n",
        "      'dropofflat' : tf.placeholder(tf.float32, [None]),\n",
        "      'dropofflon' : tf.placeholder(tf.float32, [None]),\n",
        "      'passengers' : tf.placeholder(tf.float32, [None]),\n",
        "  }\n",
        "  \n",
        "  features = {\n",
        "      key: tf.expand_dims(tensor, -1)\n",
        "      for key, tensor in feature_placeholders.items()\n",
        "  }\n",
        "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ptLP-h1C1KFO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(output_dir, num_train_steps):\n",
        "  estimator = tf.estimator.LinearRegressor(\n",
        "    model_dir = output_dir,\n",
        "    feature_columns = feature_cols)\n",
        "  train_spec = tf.estimator.TrainSpec(\n",
        "    input_fn = read_dataset('./taxi-train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
        "    max_steps = num_train_steps)\n",
        "  exporter = tf.estimator.LatestExporter('exporter',serving_input_fn)\n",
        "  eval_spec = tf.estimator.EvalSpec(\n",
        "    input_fn = read_dataset('./taxi-valid.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
        "    steps = None,\n",
        "    start_delay_secs = 1,\n",
        "    throttle_secs = 10,\n",
        "    exporters = exporter)\n",
        "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "76iApxwlBH01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2162
        },
        "outputId": "bcd8ae60-2f5d-410c-8887-8f2df804c22d"
      },
      "cell_type": "code",
      "source": [
        "outdir = 'taxi_trained'\n",
        "shutil.rmtree(outdir, ignore_errors = True)\n",
        "train_and_evaluate(outdir, num_train_steps = 5000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faa85f82908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained/model.ckpt.\n",
            "INFO:tensorflow:loss = 125890.9, step = 1\n",
            "INFO:tensorflow:global_step/sec: 60.3556\n",
            "INFO:tensorflow:loss = 43468.684, step = 101 (1.659 sec)\n",
            "INFO:tensorflow:global_step/sec: 60.7638\n",
            "INFO:tensorflow:loss = 38866.18, step = 201 (1.645 sec)\n",
            "INFO:tensorflow:global_step/sec: 60.3607\n",
            "INFO:tensorflow:loss = 38866.184, step = 301 (1.657 sec)\n",
            "INFO:tensorflow:global_step/sec: 61.3692\n",
            "INFO:tensorflow:loss = 49418.5, step = 401 (1.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 61.0937\n",
            "INFO:tensorflow:loss = 41983.434, step = 501 (1.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 60.3491\n",
            "INFO:tensorflow:loss = 40805.266, step = 601 (1.657 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.3448\n",
            "INFO:tensorflow:loss = 47686.98, step = 701 (1.578 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.4924\n",
            "INFO:tensorflow:loss = 33354.812, step = 801 (1.551 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.1183\n",
            "INFO:tensorflow:loss = 42218.188, step = 901 (1.516 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.7603\n",
            "INFO:tensorflow:loss = 38914.836, step = 1001 (1.516 sec)\n",
            "INFO:tensorflow:global_step/sec: 61.888\n",
            "INFO:tensorflow:loss = 35431.945, step = 1101 (1.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 60.0309\n",
            "INFO:tensorflow:loss = 59699.047, step = 1201 (1.668 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.7851\n",
            "INFO:tensorflow:loss = 40613.633, step = 1301 (1.698 sec)\n",
            "INFO:tensorflow:global_step/sec: 61.3919\n",
            "INFO:tensorflow:loss = 29639.523, step = 1401 (1.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 58.6735\n",
            "INFO:tensorflow:loss = 40429.684, step = 1501 (1.704 sec)\n",
            "INFO:tensorflow:global_step/sec: 59.9195\n",
            "INFO:tensorflow:loss = 45884.797, step = 1601 (1.665 sec)\n",
            "INFO:tensorflow:global_step/sec: 59.7342\n",
            "INFO:tensorflow:loss = 53272.152, step = 1701 (1.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.2955\n",
            "INFO:tensorflow:loss = 41738.36, step = 1801 (1.532 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.897\n",
            "INFO:tensorflow:loss = 40769.598, step = 1901 (1.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.8188\n",
            "INFO:tensorflow:loss = 29940.824, step = 2001 (1.543 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.3591\n",
            "INFO:tensorflow:loss = 51666.137, step = 2101 (1.507 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.624\n",
            "INFO:tensorflow:loss = 45629.562, step = 2201 (1.575 sec)\n",
            "INFO:tensorflow:global_step/sec: 61.0652\n",
            "INFO:tensorflow:loss = 44528.992, step = 2301 (1.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.0271\n",
            "INFO:tensorflow:loss = 41120.9, step = 2401 (1.586 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.9708\n",
            "INFO:tensorflow:loss = 41133.812, step = 2501 (1.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 61.9213\n",
            "INFO:tensorflow:loss = 52316.426, step = 2601 (1.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.4548\n",
            "INFO:tensorflow:loss = 47858.266, step = 2701 (1.576 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.7861\n",
            "INFO:tensorflow:loss = 43086.42, step = 2801 (1.520 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.6161\n",
            "INFO:tensorflow:loss = 31826.688, step = 2901 (1.525 sec)\n",
            "INFO:tensorflow:global_step/sec: 61.3925\n",
            "INFO:tensorflow:loss = 39180.98, step = 3001 (1.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 62.0413\n",
            "INFO:tensorflow:loss = 38428.562, step = 3101 (1.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 62.2356\n",
            "INFO:tensorflow:loss = 43835.727, step = 3201 (1.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 62.609\n",
            "INFO:tensorflow:loss = 33405.97, step = 3301 (1.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.1352\n",
            "INFO:tensorflow:loss = 43357.688, step = 3401 (1.515 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.1706\n",
            "INFO:tensorflow:loss = 30530.182, step = 3501 (1.507 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.7958\n",
            "INFO:tensorflow:loss = 35104.844, step = 3601 (1.497 sec)\n",
            "INFO:tensorflow:global_step/sec: 66.1733\n",
            "INFO:tensorflow:loss = 35840.406, step = 3701 (1.512 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.8662\n",
            "INFO:tensorflow:loss = 49786.227, step = 3801 (1.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 63.5652\n",
            "INFO:tensorflow:loss = 33252.65, step = 3901 (1.573 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.1694\n",
            "INFO:tensorflow:loss = 43358.2, step = 4001 (1.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.0879\n",
            "INFO:tensorflow:loss = 47754.11, step = 4101 (1.560 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.8669\n",
            "INFO:tensorflow:loss = 32685.24, step = 4201 (1.542 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.5887\n",
            "INFO:tensorflow:loss = 45105.71, step = 4301 (1.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 65.3835\n",
            "INFO:tensorflow:loss = 44998.65, step = 4401 (1.526 sec)\n",
            "INFO:tensorflow:global_step/sec: 62.303\n",
            "INFO:tensorflow:loss = 32899.676, step = 4501 (1.605 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.2287\n",
            "INFO:tensorflow:loss = 35062.406, step = 4601 (1.558 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.8655\n",
            "INFO:tensorflow:loss = 39559.82, step = 4701 (1.541 sec)\n",
            "INFO:tensorflow:global_step/sec: 62.1582\n",
            "INFO:tensorflow:loss = 48715.508, step = 4801 (1.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 64.5785\n",
            "INFO:tensorflow:loss = 33020.84, step = 4901 (1.549 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into taxi_trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-04-13T10:18:39Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VtYMx6nNI13u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Monitoring with TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "_dRFx6RhIske",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.datalab.ml import TensorBoard\n",
        "TensorBoard().start('./taxi_trained')\n",
        "TensorBoard().list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P0Qj3WKjOfdP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to stop TensorBoard\n",
        "for pid in TensorBoard.list()['pid']:\n",
        "    TensorBoard().stop(pid)\n",
        "    print('Stopped TensorBoard with pid {}'.format(pid))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}