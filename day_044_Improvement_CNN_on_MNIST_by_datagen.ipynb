{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day_044_Improvement_CNN_on_MNIST_by_datagen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkrissada/100DayOfMLCode/blob/master/day_044_Improvement_CNN_on_MNIST_by_datagen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pfVAsx9yR9v_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37b054ca-e1a7-4aae-d5f4-f457f788d182"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxZ_gYmGU1ab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b3bcf0e-ab92-4f7a-b783-43a80eb30032"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGJsbtd7U3S_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as k \n",
        "\n",
        "img_rows, img_cols=28, 28\n",
        "\n",
        "if k.image_data_format() == 'channels_first': \n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) \n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) \n",
        "  inpx = (1, img_rows, img_cols) \n",
        "\n",
        "else: \n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) \n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) \n",
        "  inpx = (img_rows, img_cols, 1) \n",
        "\n",
        "x_train = x_train.astype('float32') \n",
        "x_test = x_test.astype('float32') \n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xs0_egWiVBxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras  \n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train) \n",
        "y_test = keras.utils.to_categorical(y_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6wNzSPSVGV2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        zoom_range = 0.15,  \n",
        "        width_shift_range=0.1, \n",
        "        height_shift_range=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PxxIq5jMVgcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "dd7692c1-fb8a-440f-f089-9922c3852b52"
      },
      "cell_type": "code",
      "source": [
        "nets = 15\n",
        "model = [0] *nets\n",
        "for j in range(nets):\n",
        "    model[j] = Sequential()\n",
        "\n",
        "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Dropout(0.4))\n",
        "\n",
        "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Dropout(0.4))\n",
        "\n",
        "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Flatten())\n",
        "    model[j].add(Dropout(0.4))\n",
        "    model[j].add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
        "    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G97q0p7mV2AL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "543cc703-2d01-4390-9105-357acc1aa0c2"
      },
      "cell_type": "code",
      "source": [
        "# DECREASE LEARNING RATE EACH EPOCH\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
        "# TRAIN NETWORKS\n",
        "history = [0] * nets\n",
        "epochs = 45\n",
        "for j in range(nets):\n",
        "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(x_train, y_train, test_size = 0.1)\n",
        "    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
        "        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n",
        "        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)\n",
        "    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
        "        j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN 1: Epochs=1, Train accuracy=0.99290, Validation accuracy=0.99817\n",
            "CNN 2: Epochs=1, Train accuracy=0.98758, Validation accuracy=0.99550\n",
            "CNN 3: Epochs=1, Train accuracy=0.98799, Validation accuracy=0.99667\n",
            "CNN 4: Epochs=1, Train accuracy=0.98766, Validation accuracy=0.99500\n",
            "CNN 5: Epochs=1, Train accuracy=0.98753, Validation accuracy=0.99450\n",
            "CNN 6: Epochs=1, Train accuracy=0.98751, Validation accuracy=0.99567\n",
            "CNN 7: Epochs=1, Train accuracy=0.98732, Validation accuracy=0.99267\n",
            "CNN 8: Epochs=1, Train accuracy=0.98819, Validation accuracy=0.99483\n",
            "CNN 9: Epochs=1, Train accuracy=0.98884, Validation accuracy=0.99467\n",
            "CNN 10: Epochs=1, Train accuracy=0.98020, Validation accuracy=0.99267\n",
            "CNN 11: Epochs=1, Train accuracy=0.86864, Validation accuracy=0.97700\n",
            "CNN 12: Epochs=1, Train accuracy=0.87823, Validation accuracy=0.98200\n",
            "CNN 13: Epochs=1, Train accuracy=0.87643, Validation accuracy=0.97717\n",
            "CNN 14: Epochs=1, Train accuracy=0.87085, Validation accuracy=0.98433\n",
            "CNN 15: Epochs=1, Train accuracy=0.87433, Validation accuracy=0.98417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ldJNzbGKc3hR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ENSEMBLE PREDICTIONS AND SUBMIT\n",
        "results = np.zeros( (x_test.shape[0],10) ) \n",
        "for j in range(nets):\n",
        "    results = results + model[j].predict(x_test)\n",
        "results = np.argmax(results,axis = 1)\n",
        "results = pd.Series(results,name=\"Label\")\n",
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
        "submission.to_csv(\"MNIST-CNN-ENSEMBLE.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}