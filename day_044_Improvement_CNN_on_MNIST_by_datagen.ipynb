{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day_044_Improvement_CNN_on_MNIST_by_datagen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkrissada/100DayOfMLCode/blob/master/day_044_Improvement_CNN_on_MNIST_by_datagen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pfVAsx9yR9v_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37b054ca-e1a7-4aae-d5f4-f457f788d182"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxZ_gYmGU1ab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b3bcf0e-ab92-4f7a-b783-43a80eb30032"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGJsbtd7U3S_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as k \n",
        "\n",
        "img_rows, img_cols=28, 28\n",
        "\n",
        "if k.image_data_format() == 'channels_first': \n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) \n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) \n",
        "  inpx = (1, img_rows, img_cols) \n",
        "\n",
        "else: \n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) \n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) \n",
        "  inpx = (img_rows, img_cols, 1) \n",
        "\n",
        "x_train = x_train.astype('float32') \n",
        "x_test = x_test.astype('float32') \n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xs0_egWiVBxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras  \n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train) \n",
        "y_test = keras.utils.to_categorical(y_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6wNzSPSVGV2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        zoom_range = 0.15,  \n",
        "        width_shift_range=0.1, \n",
        "        height_shift_range=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PxxIq5jMVgcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "dd7692c1-fb8a-440f-f089-9922c3852b52"
      },
      "cell_type": "code",
      "source": [
        "nets = 15\n",
        "model = [0] *nets\n",
        "for j in range(nets):\n",
        "    model[j] = Sequential()\n",
        "\n",
        "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Dropout(0.4))\n",
        "\n",
        "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Dropout(0.4))\n",
        "\n",
        "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
        "    model[j].add(BatchNormalization())\n",
        "    model[j].add(Flatten())\n",
        "    model[j].add(Dropout(0.4))\n",
        "    model[j].add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
        "    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G97q0p7mV2AL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7be84f9d-93f4-4b55-c154-685e89f8985e"
      },
      "cell_type": "code",
      "source": [
        "# DECREASE LEARNING RATE BY 0.95 EACH EPOCH\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
        "\n",
        "# TRAIN CNNs AND DISPLAY ACCURACIES\n",
        "epochs = 30\n",
        "history = [0] * nets\n",
        "results = [0] * nets\n",
        "for j in range(nets):\n",
        "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(x_train, y_train, test_size = 0.1)\n",
        "    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
        "      epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,\n",
        "      validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)\n",
        "    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format\n",
        "      (j+1,epochs,history[j].history['acc'][epochs-1],history[j].history['val_acc'][epochs-1]))\n",
        "    \n",
        "    # PREDICT DIGITS FOR CNN J ON MNIST 10K TEST\n",
        "    results[j] = model[j].predict(X_test)\n",
        "    results2 = np.argmax(results[j],axis = 1)\n",
        "\n",
        "    # CALCULATE ACCURACY OF CNN J ON MNIST 10K TEST\n",
        "    c=0\n",
        "    for i in range(10000):\n",
        "        if results2[i]!=y_test[i]:\n",
        "            c +=1\n",
        "    print(\"CNN %d: Test accuracy = %f\" % (j+1,1-c/10000.))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oRpiKNqRWceJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# PREDICT DIGITS FOR ENSEMBLE ON MNIST 10K TEST\n",
        "results2 = np.zeros( (X_test.shape[0],10) )\n",
        "for j in range(nets):\n",
        "    results2 = results2 + results[j]\n",
        "results2 = np.argmax(results2,axis = 1)\n",
        " \n",
        "# CALCULATE ACCURACY OF ENSEMBLE ON MNIST 10K TEST SET    \n",
        "c=0\n",
        "for i in range(10000):\n",
        "    if results2[i]!=y_test[i]:\n",
        "        c +=1\n",
        "print(\"Ensemble Accuracy = %f\" % (1-c/10000.))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}